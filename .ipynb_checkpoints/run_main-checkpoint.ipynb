{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ce53a4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from src import HLA_Vec\n",
    "from src import utils\n",
    "from src import HLA_CNN\n",
    "from time import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b29b154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# # 配置文件\n",
    "# config = configparser.ConfigParser()\n",
    "\n",
    "# # 从程序外部输入参数的指令\n",
    "# # sys.argv[1]\n",
    "# config.read(sys.argv[1])\n",
    "# # 返回所有的配置信息\n",
    "# c = config.sections()\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3af793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始学习氨基酸的分布式表示...\n",
      "Distributed represntation will be learned based on vector dim: 15, context window: 5.\n",
      "There are 141089 peptide sequences in the source file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python3.7.7\\lib\\site-packages\\gensim\\models\\word2vec.py:813: UserWarning: C extension not loaded for Word2Vec, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  warnings.warn(\"C extension not loaded for Word2Vec, training will be slow. \"\n"
     ]
    }
   ],
   "source": [
    "HLA_Vec_params = {'vec_dim':15,'min_count':2,'window_size':5,'sg_model':'True','iter':10}\n",
    "dirnames = {'HLA-Vec_embedding':'HLA-Vec_embedding','HLA-CNN_models':'HLA-CNN_models','results':'prediction_results','train_set':'train_test_data/train_data/proteins.txt','test_set':'train_test_data/test_data/A0202'}\n",
    "\n",
    "print(\"开始学习氨基酸的分布式表示...\")\n",
    "begin_time = time()\n",
    "HLA_Vec.run(HLA_Vec_params,dirnames)\n",
    "end_time = time()\n",
    "# 这个返回的单位是秒\n",
    "print('该过程运行时间：',(end_time-begin_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73ced649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training of HLA-CNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.6495 - accuracy: 0.6659 - val_loss: 0.4865 - val_accuracy: 0.8182\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.7258 - val_loss: 0.4616 - val_accuracy: 0.8364\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7192 - val_loss: 0.4452 - val_accuracy: 0.8182\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7628 - val_loss: 0.4314 - val_accuracy: 0.8364\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7529 - val_loss: 0.4246 - val_accuracy: 0.8364\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7934 - val_loss: 0.4399 - val_accuracy: 0.8364\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7713 - val_loss: 0.4350 - val_accuracy: 0.8545\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7810 - val_loss: 0.4300 - val_accuracy: 0.8364\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8250 - val_loss: 0.4431 - val_accuracy: 0.8182\n",
      "Epoch 10/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8053 - val_loss: 0.4276 - val_accuracy: 0.7818\n",
      "Epoch 11/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8099 - val_loss: 0.4471 - val_accuracy: 0.8364\n",
      "Epoch 12/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8322 - val_loss: 0.4392 - val_accuracy: 0.8364\n",
      "Epoch 13/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8231 - val_loss: 0.4320 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8347 - val_loss: 0.3834 - val_accuracy: 0.8364\n",
      "Epoch 15/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8413 - val_loss: 0.4333 - val_accuracy: 0.8182\n",
      "Epoch 16/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8499 - val_loss: 0.4806 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8327 - val_loss: 0.3901 - val_accuracy: 0.8182\n",
      "Epoch 18/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8530 - val_loss: 0.3533 - val_accuracy: 0.8364\n",
      "Epoch 19/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8251 - val_loss: 0.4480 - val_accuracy: 0.8182\n",
      "Epoch 20/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8479 - val_loss: 0.4195 - val_accuracy: 0.8182\n",
      "Epoch 00020: early stopping\n",
      "Epoch 1/100\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.7338 - accuracy: 0.6726 - val_loss: 0.5343 - val_accuracy: 0.8182\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.7226 - val_loss: 0.4810 - val_accuracy: 0.8182\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.7218 - val_loss: 0.4761 - val_accuracy: 0.8182\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.7156 - val_loss: 0.5249 - val_accuracy: 0.8182\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.7161 - val_loss: 0.5023 - val_accuracy: 0.8182\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.7139 - val_loss: 0.4972 - val_accuracy: 0.8182\n",
      "Epoch 00006: early stopping\n",
      "Epoch 1/100\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.6504 - accuracy: 0.6974 - val_loss: 0.4837 - val_accuracy: 0.8182\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.7284 - val_loss: 0.4775 - val_accuracy: 0.8182\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7288 - val_loss: 0.4103 - val_accuracy: 0.8182\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7519 - val_loss: 0.3989 - val_accuracy: 0.8364\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7517 - val_loss: 0.4407 - val_accuracy: 0.8364\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7864 - val_loss: 0.4250 - val_accuracy: 0.8545\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7716 - val_loss: 0.3918 - val_accuracy: 0.8364\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7772 - val_loss: 0.3824 - val_accuracy: 0.8182\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7936 - val_loss: 0.4271 - val_accuracy: 0.8364\n",
      "Epoch 10/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8106 - val_loss: 0.3870 - val_accuracy: 0.8364\n",
      "Epoch 11/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8103 - val_loss: 0.3920 - val_accuracy: 0.8364\n",
      "Epoch 12/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8214 - val_loss: 0.4238 - val_accuracy: 0.8364\n",
      "Epoch 13/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8226 - val_loss: 0.3995 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8093 - val_loss: 0.3870 - val_accuracy: 0.8182\n",
      "Epoch 15/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8449 - val_loss: 0.4110 - val_accuracy: 0.8182\n",
      "Epoch 16/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8350 - val_loss: 0.3895 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8384 - val_loss: 0.4307 - val_accuracy: 0.8182\n",
      "Epoch 18/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8324 - val_loss: 0.4119 - val_accuracy: 0.8182\n",
      "Epoch 19/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8535 - val_loss: 0.4151 - val_accuracy: 0.8364\n",
      "Epoch 20/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8769 - val_loss: 0.3928 - val_accuracy: 0.8182\n",
      "Epoch 21/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8336 - val_loss: 0.4814 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8449 - val_loss: 0.4475 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8430 - val_loss: 0.4517 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8490 - val_loss: 0.4421 - val_accuracy: 0.8364\n",
      "Epoch 25/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8554 - val_loss: 0.3908 - val_accuracy: 0.8545\n",
      "Epoch 26/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8683 - val_loss: 0.4409 - val_accuracy: 0.8545\n",
      "Epoch 27/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8678 - val_loss: 0.4284 - val_accuracy: 0.8545\n",
      "Epoch 28/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8771 - val_loss: 0.4410 - val_accuracy: 0.8182\n",
      "Epoch 29/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8650 - val_loss: 0.3978 - val_accuracy: 0.8182\n",
      "Epoch 30/100\n",
      "95/95 [==============================] - 0s 3ms/step - loss: 0.3136 - accuracy: 0.8580 - val_loss: 0.4468 - val_accuracy: 0.8182\n",
      "Epoch 00030: early stopping\n",
      "Epoch 1/100\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.6248 - accuracy: 0.6899 - val_loss: 0.4714 - val_accuracy: 0.8182\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.6761 - val_loss: 0.4651 - val_accuracy: 0.8182\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7206 - val_loss: 0.4402 - val_accuracy: 0.8182\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7396 - val_loss: 0.4371 - val_accuracy: 0.8364\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7575 - val_loss: 0.4620 - val_accuracy: 0.8364\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7683 - val_loss: 0.4163 - val_accuracy: 0.8364\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7871 - val_loss: 0.3953 - val_accuracy: 0.8364\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7710 - val_loss: 0.4672 - val_accuracy: 0.8364\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8065 - val_loss: 0.4051 - val_accuracy: 0.8545\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.6405 - accuracy: 0.6829 - val_loss: 0.4738 - val_accuracy: 0.8182\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.7189 - val_loss: 0.4281 - val_accuracy: 0.8182\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.7054 - val_loss: 0.4266 - val_accuracy: 0.8182\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.7070 - val_loss: 0.4179 - val_accuracy: 0.8364\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7520 - val_loss: 0.4190 - val_accuracy: 0.8182\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7699 - val_loss: 0.3991 - val_accuracy: 0.8364\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7953 - val_loss: 0.4338 - val_accuracy: 0.8364\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7908 - val_loss: 0.4217 - val_accuracy: 0.8364\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7954 - val_loss: 0.4106 - val_accuracy: 0.8545\n",
      "Epoch 10/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8184 - val_loss: 0.4380 - val_accuracy: 0.8182\n",
      "Epoch 11/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8073 - val_loss: 0.3890 - val_accuracy: 0.8364\n",
      "Epoch 12/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8243 - val_loss: 0.4522 - val_accuracy: 0.8182\n",
      "Epoch 13/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8133 - val_loss: 0.4628 - val_accuracy: 0.8364\n",
      "Epoch 14/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8280 - val_loss: 0.4042 - val_accuracy: 0.8364\n",
      "Epoch 15/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8342 - val_loss: 0.3667 - val_accuracy: 0.8182\n",
      "Epoch 16/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8363 - val_loss: 0.3836 - val_accuracy: 0.8364\n",
      "Epoch 17/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8395 - val_loss: 0.4137 - val_accuracy: 0.8364\n",
      "Epoch 18/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8485 - val_loss: 0.4343 - val_accuracy: 0.8182\n",
      "Epoch 19/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8535 - val_loss: 0.5012 - val_accuracy: 0.8182\n",
      "Epoch 20/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8506 - val_loss: 0.4573 - val_accuracy: 0.8182\n",
      "Epoch 21/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8482 - val_loss: 0.4060 - val_accuracy: 0.8364\n",
      "Epoch 22/100\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8430 - val_loss: 0.4294 - val_accuracy: 0.8364\n",
      "Epoch 00022: early stopping\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting the training of HLA-CNN...\")\n",
    "HLA_CNN_params = {'epochs':100,'lr':.004,'filter_length':7,'filter_size':32,'dropout':.25}\n",
    "HLA_CNN.train(HLA_CNN_params,dirnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63b00b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing evaluation on the test set...\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D1BB7A51F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "SRCC: 0.03\n",
      "AUC: 0.52\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing evaluation on the test set...\")\n",
    "HLA_CNN.evaluate(dirnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bb2cc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing inference on the test set...\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D1BC083D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing inference on the test set...\")\n",
    "HLA_CNN.inference(dirnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5721919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
